---
layout: default
title: Planning & Requirements
---

# Planning & Requirements

<div class="glass-card">
Every great project starts with a problem worth solving. Let me take you back to where this all began.
</div>

## The Problem

It was late October 2024, and I was drowning in research papers. I was trying to stay current with advances in transformer architectures, RAG systems, and multi-agent frameworks - but new papers were being published faster than I could read them.

I'd spend hours:
- Searching across arXiv, Semantic Scholar, PubMed
- Copying paper titles and abstracts into notes
- Trying to remember which paper mentioned what concept
- Re-reading papers because I forgot their key insights

**There had to be a better way.**

## The Vision

I imagined a research assistant that could:

1. **Automatically collect** papers from multiple sources based on my interests
2. **Build a knowledge graph** showing how papers, authors, and concepts relate
3. **Answer my questions** by synthesizing information across papers
4. **Remember our conversations** so I don't have to repeat context
5. **Scale** from my laptop to production without rewriting code

But I didn't want to build just another prototype. I wanted something that demonstrated **production-grade patterns** I could use in real applications.

## Core Requirements

I broke this down into functional and non-functional requirements.

<div class="glass-card">

### Functional Requirements

**Data Collection**
- âœ… Support multiple data sources (academic databases, web search)
- âœ… Automatic deduplication of papers
- âœ… Scheduled/automated collection in background
- âœ… Rate limiting and error handling

**Knowledge Organization**
- âœ… Knowledge graph with entities (papers, authors, topics)
- âœ… Relationships (authored, cites, is_about)
- âœ… Vector embeddings for semantic search
- âœ… Graph visualization

**Query & Reasoning**
- âœ… Natural language question answering
- âœ… Multi-hop reasoning across papers
- âœ… Source citation with paper references
- âœ… Conversation memory (5-turn history)

**Session Management**
- âœ… Multiple research sessions
- âœ… Save/load session state
- âœ… Session statistics and metadata

**User Interface**
- âœ… Modern, responsive web interface
- âœ… Data collection controls
- âœ… Interactive graph visualization
- âœ… Chat interface for queries

</div>

<div class="glass-card">

### Non-Functional Requirements

**Performance**
- Data collection: < 2 minutes for 10+ papers
- Query answering: < 5 seconds
- Graph queries: < 100ms
- Vector search: < 100ms

**Reliability**
- 99% uptime for production deployment
- Graceful degradation if services unavailable
- Automatic retries with exponential backoff
- Circuit breakers for external APIs

**Scalability**
- Support 1000+ papers in knowledge base
- Handle concurrent users in production
- Horizontal scaling with Kafka
- Efficient caching to reduce costs

**Maintainability**
- 90%+ test coverage
- Type safety with TypeScript/Pydantic
- Clear separation of concerns
- Comprehensive documentation

**Cost Efficiency**
- Intelligent model selection (use cheapest model for each task)
- Caching to avoid redundant API calls
- Token budgets to prevent runaway costs
- Target: < $10/month for moderate usage

</div>

## Choosing the Tech Stack

This was one of the most important decisions. I needed technologies that were:
- **Mature** enough for production
- **Well-documented** so I could move fast
- **Composable** so I could swap components
- **Cost-effective** to run

Here's how I evaluated each component:

### LLM Provider

**Candidates**: OpenAI GPT-4, Anthropic Claude, Google Gemini

**Winner**: **Google Gemini 2.0 Flash**

**Why?**
- âœ… Fast response times (< 2s average)
- âœ… Cost-effective ($0.35 per 1M tokens)
- âœ… Large context window (1M tokens)
- âœ… Good reasoning capabilities
- âœ… Free tier for development

I experimented with all three, and Gemini gave the best balance of speed, cost, and quality for research Q&A.

### Orchestration Framework

**Candidates**: LangChain, LangGraph, Custom

**Winner**: **LangGraph**

**Why?**
- âœ… Built for multi-agent workflows
- âœ… Excellent state management
- âœ… Visual workflow debugging
- âœ… Works seamlessly with LlamaIndex
- âœ… Good documentation and examples

LangChain was too linear for my multi-agent pattern. LangGraph gave me the graph-based orchestration I needed.

### RAG Framework

**Candidates**: LlamaIndex, Haystack, Custom

**Winner**: **LlamaIndex**

**Why?**
- âœ… Best-in-class retrieval strategies
- âœ… Flexible architecture
- âœ… Great integration with vector DBs
- âœ… Built-in evaluation tools
- âœ… Active community

LlamaIndex saved me weeks of work on chunking strategies, embedding management, and retrieval optimization.

### Knowledge Graph

**Candidates**: Neo4j, NetworkX, TigerGraph

**Winner**: **Both Neo4j AND NetworkX** (dual backend)

**Why?**
- âœ… Neo4j for production (persistent, scalable, visual)
- âœ… NetworkX for development (fast startup, no infrastructure)
- âœ… Same API for both (abstraction layer)
- âœ… Easy switching via environment variables

This was a game-changer. I could develop and test on my laptop with NetworkX, then deploy to production with Neo4j without changing code.

### Vector Database

**Candidates**: Pinecone, Weaviate, Qdrant, FAISS

**Winner**: **Both Qdrant AND FAISS** (dual backend)

**Why?**
- âœ… Qdrant for production (persistent, REST API, dashboard)
- âœ… FAISS for development (in-memory, no setup)
- âœ… Same abstraction layer
- âœ… Cost: $0 (self-hosted Qdrant)

Again, dual backends gave me the flexibility to move fast in development and scale in production.

### Event Streaming

**Candidates**: Kafka, RabbitMQ, Redis Streams

**Winner**: **Kafka** (optional)

**Why?**
- âœ… Industry standard for event-driven systems
- âœ… Event persistence and replay
- âœ… Horizontal scaling with consumer groups
- âœ… Rich ecosystem (Kafka UI, connectors)
- âœ… Optional: falls back to sync mode if unavailable

I made Kafka optional because it's overkill for development but essential for production scalability.

### ETL Orchestration

**Candidates**: Airflow, Prefect, Dagster

**Winner**: **Apache Airflow**

**Why?**
- âœ… Industry standard for data pipelines
- âœ… Visual DAG editor and monitoring
- âœ… Automatic retries and error handling
- âœ… Scalable with Celery workers
- âœ… Rich integrations

Airflow gave me 3-4x faster data collection through parallel execution and automatic retries.

### Frontend

**Candidates**: Next.js, Vite+React, SvelteKit

**Winner**: **Vite + React + TypeScript**

**Why?**
- âœ… Lightning fast dev server (< 1s HMR)
- âœ… React ecosystem and component libraries
- âœ… TypeScript for type safety
- âœ… Lightweight (no SSR overhead)
- âœ… Easy deployment

I didn't need SSR for this app, so Vite's simplicity and speed won.

## Architecture Philosophy

I made some key architectural decisions early on:

<div class="glass-card">

### 1. Dual-Backend Strategy

**Problem**: Setting up Neo4j, Qdrant, and Kafka for development is slow and resource-heavy.

**Solution**: Abstract backends behind interfaces, provide in-memory alternatives.

**Benefits**:
- âš¡ Instant startup in development (0s vs 30s)
- ğŸ§ª Faster test suite (no Docker overhead)
- ğŸ’° Lower cloud costs (single container vs 7)
- ğŸ”„ Easy switching via env vars

</div>

<div class="glass-card">

### 2. Multi-Agent Pattern

**Problem**: A single monolithic agent becomes complex and hard to test.

**Solution**: Separate concerns into specialized agents coordinated by an orchestrator.

**Benefits**:
- ğŸ§© Clear separation of concerns
- ğŸ§ª Easier unit testing
- ğŸ”„ Can replace individual agents
- ğŸ“ˆ Can scale agents independently

</div>

<div class="glass-card">

### 3. Event-Driven Communication

**Problem**: Synchronous agent calls create tight coupling and bottlenecks.

**Solution**: Agents publish events to Kafka; consumers process asynchronously.

**Benefits**:
- âš¡ Parallel processing (3x faster)
- ğŸ”Œ Loose coupling
- ğŸ”„ Event replay for debugging
- ğŸ“ˆ Horizontal scaling

</div>

<div class="glass-card">

### 4. Production-Grade Patterns

From day one, I implemented patterns that would matter at scale:

**Circuit Breakers**: Prevent cascade failures when APIs go down
```python
@circuit_breaker(failure_threshold=5, recovery_timeout=60)
def call_external_api():
    ...
```

**Token Budgets**: Prevent runaway LLM costs
```python
@token_budget(per_request=10000, per_user=100000)
def generate_answer():
    ...
```

**Intelligent Caching**: 40% cost reduction with dual-tier cache
```python
@cache(ttl=3600, strategy="dual-tier")
def expensive_operation():
    ...
```

**Dynamic Model Selection**: Use cheapest model that meets requirements
```python
model = select_model(task_type="summarization", max_latency=2.0)
```

</div>

## The Plan

With requirements and architecture decided, I created a development plan:

**Phase 1: Core Agents (Week 1)**
- [x] Set up project structure
- [x] Implement DataCollectorAgent with 3 sources
- [x] Implement KnowledgeGraphAgent with NetworkX
- [x] Implement VectorAgent with FAISS
- [x] Implement ReasoningAgent with Gemini
- [x] Basic OrchestratorAgent

**Phase 2: Production Features (Week 2)**
- [x] Add Neo4j backend for graphs
- [x] Add Qdrant backend for vectors
- [x] Implement Kafka event system
- [x] Add 4 more data sources
- [x] Implement SchedulerAgent
- [x] Session management and persistence
- [x] Apache Airflow integration

**Phase 3: Frontend & Testing (Week 3)**
- [x] React frontend with glassmorphism design
- [x] 7 pages (Home, Collect, Ask, Graph, Vector, Upload, Sessions)
- [x] Comprehensive test suite (90%+ coverage)
- [x] GitHub Actions CI/CD
- [x] Docker containerization
- [x] Documentation

## Lessons from Planning

Looking back, here's what I learned:

**âœ… What Worked**

1. **Dual-backend strategy was brilliant** - Saved hours of dev time
2. **Starting with requirements** - Kept me focused
3. **Choosing mature tech** - Less debugging, more building
4. **Production patterns from day 1** - No painful refactoring later

**ğŸ¤” What I'd Change**

1. **Should have added Airflow earlier** - Parallel collection is much faster
2. **Could have started with fewer data sources** - 3 would have been enough to validate
3. **Frontend design took longer than expected** - Glassmorphism is tricky to get right

**ğŸ’¡ Key Insights**

> The best architecture is one that lets you move fast in development and scale in production without rewriting code.

> Abstractions are worth the upfront cost when they give you optionality.

> Production patterns implemented early save painful refactoring later.

## Ready for Architecture?

Now that you understand the "why" behind ResearcherAI, let's dive into the "how". In the next section, I'll walk you through the system architecture and how all these pieces fit together.

<div class="progress-nav">
  <a href="index.html">â† Back to Home</a>
  <a href="02-architecture.html">Next: Architecture Design â†’</a>
</div>
